------- Begin to search for MOVIES -------
16/12/12 15:29:51 INFO spark.SparkContext: Running Spark version 1.6.0
16/12/12 15:29:51 INFO spark.SecurityManager: Changing view acls to: wl1485
16/12/12 15:29:51 INFO spark.SecurityManager: Changing modify acls to: wl1485
16/12/12 15:29:51 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wl1485); users with modify permissions: Set(wl1485)
16/12/12 15:29:51 INFO util.Utils: Successfully started service 'sparkDriver' on port 40973.
16/12/12 15:29:52 INFO slf4j.Slf4jLogger: Slf4jLogger started
16/12/12 15:29:52 INFO Remoting: Starting remoting
16/12/12 15:29:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.255.254:51777]
16/12/12 15:29:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.0.255.254:51777]
16/12/12 15:29:52 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 51777.
16/12/12 15:29:52 INFO spark.SparkEnv: Registering MapOutputTracker
16/12/12 15:29:52 INFO spark.SparkEnv: Registering BlockManagerMaster
16/12/12 15:29:52 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-6b76c7bf-4fb7-4b75-a97a-bd206ee1d115
16/12/12 15:29:52 INFO storage.MemoryStore: MemoryStore started with capacity 530.3 MB
16/12/12 15:29:52 INFO spark.SparkEnv: Registering OutputCommitCoordinator
16/12/12 15:29:52 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
16/12/12 15:29:52 INFO util.Utils: Successfully started service 'SparkUI' on port 4041.
16/12/12 15:29:52 INFO ui.SparkUI: Started SparkUI at http://10.0.255.254:4041
16/12/12 15:29:52 INFO spark.SparkContext: Added JAR file:/home/wl1485/project/trendalytics/target/trendalytics-0.0.1.jar at spark://10.0.255.254:40973/jars/trendalytics-0.0.1.jar with timestamp 1481574592600
16/12/12 15:29:52 INFO client.RMProxy: Connecting to ResourceManager at babar.es.its.nyu.edu/128.122.215.50:8032
16/12/12 15:29:52 INFO yarn.Client: Requesting a new application from cluster with 44 NodeManagers
16/12/12 15:29:52 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (65536 MB per container)
16/12/12 15:29:52 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
16/12/12 15:29:52 INFO yarn.Client: Setting up container launch context for our AM
16/12/12 15:29:52 INFO yarn.Client: Setting up the launch environment for our AM container
16/12/12 15:29:52 INFO yarn.Client: Preparing resources for our AM container
16/12/12 15:29:53 INFO yarn.Client: Uploading resource file:/tmp/spark-c703ba4f-d3b3-4241-acc8-48d29d080e3d/__spark_conf__540242060907921861.zip -> hdfs://babar.es.its.nyu.edu:8020/user/wl1485/.sparkStaging/application_1480358343656_19645/__spark_conf__540242060907921861.zip
16/12/12 15:29:53 INFO spark.SecurityManager: Changing view acls to: wl1485
16/12/12 15:29:53 INFO spark.SecurityManager: Changing modify acls to: wl1485
16/12/12 15:29:53 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wl1485); users with modify permissions: Set(wl1485)
16/12/12 15:29:53 INFO yarn.Client: Submitting application 19645 to ResourceManager
16/12/12 15:29:53 INFO impl.YarnClientImpl: Submitted application application_1480358343656_19645
16/12/12 15:29:54 INFO yarn.Client: Application report for application_1480358343656_19645 (state: ACCEPTED)
16/12/12 15:29:54 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: root.wl1485
	 start time: 1481574593687
	 final status: UNDEFINED
	 tracking URL: http://babar.es.its.nyu.edu:8088/proxy/application_1480358343656_19645/
	 user: wl1485
16/12/12 15:29:55 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
16/12/12 15:29:55 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> babar.es.its.nyu.edu, PROXY_URI_BASES -> http://babar.es.its.nyu.edu:8088/proxy/application_1480358343656_19645), /proxy/application_1480358343656_19645
16/12/12 15:29:55 INFO yarn.Client: Application report for application_1480358343656_19645 (state: ACCEPTED)
16/12/12 15:29:55 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
16/12/12 15:29:56 INFO yarn.Client: Application report for application_1480358343656_19645 (state: RUNNING)
16/12/12 15:29:56 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.0.255.210
	 ApplicationMaster RPC port: 0
	 queue: root.wl1485
	 start time: 1481574593687
	 final status: UNDEFINED
	 tracking URL: http://babar.es.its.nyu.edu:8088/proxy/application_1480358343656_19645/
	 user: wl1485
16/12/12 15:29:56 INFO cluster.YarnClientSchedulerBackend: Application application_1480358343656_19645 has started running.
16/12/12 15:29:56 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33134.
16/12/12 15:29:56 INFO netty.NettyBlockTransferService: Server created on 33134
16/12/12 15:29:56 INFO storage.BlockManager: external shuffle service port = 7337
16/12/12 15:29:56 INFO storage.BlockManagerMaster: Trying to register BlockManager
16/12/12 15:29:56 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.255.254:33134 with 530.3 MB RAM, BlockManagerId(driver, 10.0.255.254, 33134)
16/12/12 15:29:56 INFO storage.BlockManagerMaster: Registered BlockManager
16/12/12 15:29:56 INFO scheduler.EventLoggingListener: Logging events to hdfs://babar.es.its.nyu.edu:8020/user/spark/applicationHistory/application_1480358343656_19645
16/12/12 15:29:56 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
16/12/12 15:29:57 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.3 KB, free 198.3 KB)
16/12/12 15:29:57 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 221.5 KB)
16/12/12 15:29:57 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.255.254:33134 (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:29:57 INFO spark.SparkContext: Created broadcast 0 from textFile at modelSaveLoad.scala:129
16/12/12 15:29:57 INFO mapred.FileInputFormat: Total input paths to process : 1
16/12/12 15:29:57 INFO spark.SparkContext: Starting job: first at modelSaveLoad.scala:129
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Got job 0 (first at modelSaveLoad.scala:129) with 1 output partitions
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (first at modelSaveLoad.scala:129)
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Parents of final stage: List()
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Missing parents: List()
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (trendalytics_data/tweets_processed/KMeansModel/metadata MapPartitionsRDD[1] at textFile at modelSaveLoad.scala:129), which has no missing parents
16/12/12 15:29:57 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 224.7 KB)
16/12/12 15:29:57 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1852.0 B, free 226.5 KB)
16/12/12 15:29:57 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.255.254:33134 (size: 1852.0 B, free: 530.3 MB)
16/12/12 15:29:57 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
16/12/12 15:29:57 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (trendalytics_data/tweets_processed/KMeansModel/metadata MapPartitionsRDD[1] at textFile at modelSaveLoad.scala:129)
16/12/12 15:29:57 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks
16/12/12 15:29:58 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
16/12/12 15:30:01 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-3-2.local:50128) with ID 1
16/12/12 15:30:01 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
16/12/12 15:30:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, compute-3-2.local, partition 0,NODE_LOCAL, 2277 bytes)
16/12/12 15:30:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-3-2.local:54058 with 530.3 MB RAM, BlockManagerId(1, compute-3-2.local, 54058)
16/12/12 15:30:02 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on compute-3-2.local:54058 (size: 1852.0 B, free: 530.3 MB)
16/12/12 15:30:02 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-3-2.local:54058 (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:30:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2750 ms on compute-3-2.local (1/1)
16/12/12 15:30:04 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/12/12 15:30:04 INFO scheduler.DAGScheduler: ResultStage 0 (first at modelSaveLoad.scala:129) finished in 6.275 s
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Job 0 finished: first at modelSaveLoad.scala:129, took 6.390286 s
16/12/12 15:30:04 INFO parquet.ParquetRelation: Listing hdfs://babar.es.its.nyu.edu:8020/user/wl1485/trendalytics_data/tweets_processed/KMeansModel/data on driver
16/12/12 15:30:04 INFO spark.SparkContext: Starting job: parquet at KMeansModel.scala:145
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Got job 1 (parquet at KMeansModel.scala:145) with 2 output partitions
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (parquet at KMeansModel.scala:145)
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Missing parents: List()
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at parquet at KMeansModel.scala:145), which has no missing parents
16/12/12 15:30:04 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 70.3 KB, free 296.8 KB)
16/12/12 15:30:04 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.8 KB, free 321.5 KB)
16/12/12 15:30:04 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.255.254:33134 (size: 24.8 KB, free: 530.2 MB)
16/12/12 15:30:04 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
16/12/12 15:30:04 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at parquet at KMeansModel.scala:145)
16/12/12 15:30:04 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
16/12/12 15:30:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, compute-3-2.local, partition 0,PROCESS_LOCAL, 2039 bytes)
16/12/12 15:30:04 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-3-2.local:54058 (size: 24.8 KB, free: 530.2 MB)
16/12/12 15:30:04 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, compute-3-2.local, partition 1,PROCESS_LOCAL, 2161 bytes)
16/12/12 15:30:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 109 ms on compute-3-2.local (1/2)
16/12/12 15:30:05 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.255.254:33134 in memory (size: 1852.0 B, free: 530.2 MB)
16/12/12 15:30:05 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on compute-3-2.local:54058 in memory (size: 1852.0 B, free: 530.2 MB)
16/12/12 15:30:05 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.255.254:33134 in memory (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:30:05 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on compute-3-2.local:54058 in memory (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:30:05 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1141 ms on compute-3-2.local (2/2)
16/12/12 15:30:05 INFO scheduler.DAGScheduler: ResultStage 1 (parquet at KMeansModel.scala:145) finished in 1.241 s
16/12/12 15:30:05 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/12/12 15:30:05 INFO scheduler.DAGScheduler: Job 1 finished: parquet at KMeansModel.scala:145, took 1.288936 s
16/12/12 15:30:06 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 99.2 KB, free 194.3 KB)
16/12/12 15:30:06 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.3 KB, free 217.6 KB)
16/12/12 15:30:06 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.255.254:33134 (size: 23.3 KB, free: 530.2 MB)
16/12/12 15:30:06 INFO spark.SparkContext: Created broadcast 3 from map at KMeansModel.scala:147
16/12/12 15:30:06 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
16/12/12 15:30:06 INFO parquet.ParquetRelation: Reading Parquet file(s) from hdfs://babar.es.its.nyu.edu:8020/user/wl1485/trendalytics_data/tweets_processed/KMeansModel/data/part-r-00000-a4f3fc06-a2a0-4bbf-ad23-144eaf412d22.gz.parquet, hdfs://babar.es.its.nyu.edu:8020/user/wl1485/trendalytics_data/tweets_processed/KMeansModel/data/part-r-00001-a4f3fc06-a2a0-4bbf-ad23-144eaf412d22.gz.parquet
16/12/12 15:30:06 INFO spark.SparkContext: Starting job: collect at KMeansModel.scala:147
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Got job 2 (collect at KMeansModel.scala:147) with 2 output partitions
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (collect at KMeansModel.scala:147)
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Missing parents: List()
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at map at KMeansModel.scala:147), which has no missing parents
16/12/12 15:30:06 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.8 KB, free 222.3 KB)
16/12/12 15:30:06 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.7 KB, free 225.0 KB)
16/12/12 15:30:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.255.254:33134 (size: 2.7 KB, free: 530.2 MB)
16/12/12 15:30:06 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
16/12/12 15:30:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at KMeansModel.scala:147)
16/12/12 15:30:06 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
16/12/12 15:30:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, compute-3-2.local, partition 0,RACK_LOCAL, 2318 bytes)
16/12/12 15:30:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on compute-3-2.local:54058 (size: 2.7 KB, free: 530.3 MB)
16/12/12 15:30:06 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on compute-3-2.local:54058 (size: 23.3 KB, free: 530.2 MB)
16/12/12 15:30:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 545 ms on compute-3-2.local (1/2)
16/12/12 15:30:07 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
16/12/12 15:30:09 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, compute-3-2.local, partition 1,ANY, 2320 bytes)
16/12/12 15:30:09 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 65 ms on compute-3-2.local (2/2)
16/12/12 15:30:09 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/12/12 15:30:09 INFO scheduler.DAGScheduler: ResultStage 2 (collect at KMeansModel.scala:147) finished in 3.375 s
16/12/12 15:30:09 INFO scheduler.DAGScheduler: Job 2 finished: collect at KMeansModel.scala:147, took 3.490267 s
DOCTOR STRANGE rated as: 6.8
Film (I watched) of the year is probably Deadpool? followed by Doctor Strange and then Civil War. I should probably watch Snowden though
Mon Dec 12 15:28:04 EST 2016
Adding annotator tokenize
Adding annotator ssplit

Adding annotator parse
Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ...16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.255.254:33134 in memory (size: 2.7 KB, free: 530.2 MB)
16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on compute-3-2.local:54058 in memory (size: 2.7 KB, free: 530.2 MB)
16/12/12 15:30:11 INFO spark.ContextCleaner: Cleaned accumulator 3
16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.255.254:33134 in memory (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on compute-3-2.local:54058 in memory (size: 23.3 KB, free: 530.3 MB)
16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.255.254:33134 in memory (size: 24.8 KB, free: 530.3 MB)
16/12/12 15:30:11 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on compute-3-2.local:54058 in memory (size: 24.8 KB, free: 530.3 MB)
done [0.5 sec].
Adding annotator sentiment
(### Sentiment is: ,1)
Exception in thread "main" java.lang.IllegalArgumentException: requirement failed
	at scala.Predef$.require(Predef.scala:221)
	at org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:330)
	at org.apache.spark.mllib.clustering.KMeans$.fastSquaredDistance(KMeans.scala:595)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$findClosest$1.apply(KMeans.scala:569)
	at org.apache.spark.mllib.clustering.KMeans$$anonfun$findClosest$1.apply(KMeans.scala:563)
	at scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:73)
	at org.apache.spark.mllib.clustering.KMeans$.findClosest(KMeans.scala:563)
	at org.apache.spark.mllib.clustering.KMeansModel.predict(KMeansModel.scala:60)
	at com.trendalytics.StreamerUtil$$anonfun$storeTweets$1.apply$mcV$sp(TwitterStreamer.scala:80)
	at scala.util.control.Breaks.breakable(Breaks.scala:37)
	at com.trendalytics.StreamerUtil$.storeTweets(TwitterStreamer.scala:69)
	at com.trendalytics.StreamerUtil$$anonfun$filterKeyTweets$1.apply(TwitterStreamer.scala:91)
	at com.trendalytics.StreamerUtil$$anonfun$filterKeyTweets$1.apply(TwitterStreamer.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at com.trendalytics.StreamerUtil$.filterKeyTweets(TwitterStreamer.scala:89)
	at com.trendalytics.TwitterStreamer.fetch(TwitterStreamer.scala:155)
	at com.trendalytics.Predict$.main(Predict.scala:43)
	at com.trendalytics.Predict.main(Predict.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
16/12/12 15:30:11 INFO spark.SparkContext: Invoking stop() from shutdown hook
16/12/12 15:30:12 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.255.254:4041
16/12/12 15:30:12 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
16/12/12 15:30:12 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
16/12/12 15:30:12 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
16/12/12 15:30:12 INFO cluster.YarnClientSchedulerBackend: Stopped
16/12/12 15:30:12 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/12/12 15:30:12 INFO storage.MemoryStore: MemoryStore cleared
16/12/12 15:30:12 INFO storage.BlockManager: BlockManager stopped
16/12/12 15:30:12 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
16/12/12 15:30:12 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/12/12 15:30:12 INFO spark.SparkContext: Successfully stopped SparkContext
16/12/12 15:30:12 INFO util.ShutdownHookManager: Shutdown hook called
16/12/12 15:30:12 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-c703ba4f-d3b3-4241-acc8-48d29d080e3d
